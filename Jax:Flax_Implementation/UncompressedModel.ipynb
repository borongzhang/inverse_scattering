{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2980328-640d-47e6-afd2-d57030413ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 12:22:19.399695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "from clu import metric_writers\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import lax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import optax\n",
    "import orbax.checkpoint as ocp\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py\n",
    "import natsort\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import geometric_transform\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3443b94d-40b8-40b0-8a77-bb6dfd050389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cuda(id=0), cuda(id=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70692656-b0fa-4d2f-97e4-b6d703121375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the computational task.\n",
    "\n",
    "L = 4 # number of levels (even number)\n",
    "s = 5 # leaf size\n",
    "r = 3 # rank\n",
    "\n",
    "# Discretization of Omega (n_eta * n_eta).\n",
    "neta = (2**L)*s\n",
    "\n",
    "# Number of sources/detectors (n_sc).\n",
    "# Discretization of the domain of alpha in polar coordinates (n_theta * n_rho).\n",
    "# For simplicity, these values are set equal (n_sc = n_theta = n_rho), facilitating computation.\n",
    "nx = (2**L)*s\n",
    "\n",
    "# Standard deviation for the Gaussian blur.\n",
    "blur_sigma = 0.5\n",
    "\n",
    "# Batch size.\n",
    "batch_size = 16\n",
    "\n",
    "# Number of training datapoints.\n",
    "NTRAIN = 2000\n",
    "\n",
    "# Number of testing datapoints.\n",
    "NTEST = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5447cb-3303-487a-95eb-7ba6f59ada8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart_polar(coords):\n",
    "    \"\"\"\n",
    "    Transforms coordinates from Cartesian to polar coordinates with custom scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - coords: A tuple or list containing the (i, j) coordinates to be transformed.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple (rho, theta) representing the transformed coordinates.\n",
    "    \"\"\"\n",
    "    i, j = coords[0], coords[1]\n",
    "    # Calculate the radial distance with a scaling factor.\n",
    "    rho = 2 * np.sqrt((i - neta / 2) ** 2 + (j - neta / 2) ** 2) * nx / neta\n",
    "    # Calculate the angle in radians and adjust the scale to fit the specified range.\n",
    "    theta = ((np.arctan2((neta / 2 - j), (i - neta / 2))) % (2 * np.pi)) * nx / np.pi / 2\n",
    "    return theta, rho + neta // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe182499-eba6-4333-b448-7ce6dc6d8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to precompute the transformation matrix\n",
    "# Precompute the transformation matrix from polar coordinates to Cartesian coordiantes \n",
    "cart_mat = np.zeros((neta**2, nx, nx))\n",
    "\n",
    "for i in range(nx):\n",
    "    for j in range(nx):\n",
    "        # Create a dummy matrix with a single one at position (i, j) and zeros elsewhere.\n",
    "        mat_dummy = np.zeros((nx, nx))\n",
    "        mat_dummy[i, j] = 1\n",
    "        # Pad the dummy matrix in polar coordinates to cover the target space in Cartesian coordinates.\n",
    "        pad_dummy = np.pad(mat_dummy, ((0, 0), (neta // 2, neta // 2)), 'edge')\n",
    "        # Apply the geometric transformation to map the dummy matrix to polar coordinates\n",
    "        cart_mat[:, i, j] = geometric_transform(pad_dummy, cart_polar, output_shape=[neta, neta], mode='grid-wrap').flatten()\n",
    "\n",
    "cart_mat = np.reshape(cart_mat, (neta**2, nx**2))\n",
    "# Removing small values\n",
    "cart_mat = np.where(np.abs(cart_mat) > 0.001, cart_mat, 0)\n",
    "# Convert to sparse matrix in tensorflow\n",
    "#cart_mat = tf.sparse.from_dense(tf.cast(cart_mat, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24ca0d4-2e8e-4faf-b847-002bd2bc60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import sparse\n",
    "cart_mat = sparse.BCOO.fromdense(cart_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520c961d-da9c-443b-aec0-8747b1f872fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "name = 'shepp_logan'\n",
    "\n",
    "# Loading and preprocessing perturbation data (eta)\n",
    "with h5py.File(f'{name}/eta.h5', 'r') as f:\n",
    "    # Read eta data, apply Gaussian blur, and reshape\n",
    "    eta_re = f[list(f.keys())[0]][:NTRAIN, :].reshape(-1, neta, neta)\n",
    "    blur_fn = lambda x: gaussian_filter(x, sigma=blur_sigma)\n",
    "    eta_re = np.stack([blur_fn(eta_re[i, :, :].T) for i in range(NTRAIN)]).astype('float32')\n",
    "\n",
    "# Loading and preprocessing scatter data (Lambda)\n",
    "with h5py.File(f'{name}/scatter.h5', 'r') as f:\n",
    "    keys = natsort.natsorted(f.keys())\n",
    "\n",
    "    # Process real part of scatter data\n",
    "    tmp1 = f[keys[3]][:NTRAIN, :]\n",
    "    tmp2 = f[keys[4]][:NTRAIN, :]\n",
    "    tmp3 = f[keys[5]][:NTRAIN, :]\n",
    "    scatter_re = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "\n",
    "    # Process imaginary part of scatter data\n",
    "    tmp1 = f[keys[0]][:NTRAIN, :]\n",
    "    tmp2 = f[keys[1]][:NTRAIN, :]\n",
    "    tmp3 = f[keys[2]][:NTRAIN, :]\n",
    "    scatter_im = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "    \n",
    "    # Combine real and imaginary parts\n",
    "    scatter = np.stack((scatter_re, scatter_im), axis=1).astype('float32')\n",
    "    \n",
    "# Clean up temporary variables to free memory\n",
    "del scatter_re, scatter_im, tmp1, tmp2, tmp3\n",
    "\n",
    "## Create a TensorFlow dataset for training\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((scatter, eta_re))\n",
    "#dataset = dataset.shuffle(buffer_size=500)\n",
    "#dataset = dataset.batch(batch_size)\n",
    "#dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "#dataset = data_loader = dataset.as_numpy_iterator()\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "dataset = [(scatter[i,:,:,:], eta_re[i,:,:]) for i in range(NTRAIN)]\n",
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995e72b6-2b15-422a-88ae-5f5a4f223f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the F^* layer using Flax\n",
    "class Fstar(nn.Module):\n",
    "    nx: int\n",
    "    neta: int\n",
    "    cart_mat: jnp.ndarray\n",
    "\n",
    "    def setup(self):\n",
    "        kernel_shape = (self.nx, self.nx)\n",
    "        p_shape = (1, self.nx)\n",
    "        \n",
    "        self.pre1 = self.param('pre1', nn.initializers.glorot_uniform(), p_shape)\n",
    "        self.pre2 = self.param('pre2', nn.initializers.glorot_uniform(), p_shape)\n",
    "        self.pre3 = self.param('pre3', nn.initializers.glorot_uniform(), p_shape)\n",
    "        self.pre4 = self.param('pre4', nn.initializers.glorot_uniform(), p_shape)\n",
    "\n",
    "        self.post1 = self.param('post1', nn.initializers.glorot_uniform(), p_shape)\n",
    "        self.post2 = self.param('post2', nn.initializers.glorot_uniform(), p_shape)\n",
    "        self.post3 = self.param('post3', nn.initializers.glorot_uniform(), p_shape)\n",
    "        self.post4 = self.param('post4', nn.initializers.glorot_uniform(), p_shape)\n",
    "        \n",
    "        self.cos_kernel1 = self.param('cos_kernel1', nn.initializers.glorot_uniform(), kernel_shape)\n",
    "        self.sin_kernel1 = self.param('sin_kernel1', nn.initializers.glorot_uniform(), kernel_shape)\n",
    "        self.cos_kernel2 = self.param('cos_kernel2', nn.initializers.glorot_uniform(), kernel_shape)\n",
    "        self.sin_kernel2 = self.param('sin_kernel2', nn.initializers.glorot_uniform(), kernel_shape)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Separate real and imaginary parts of inputs\n",
    "        R, I = inputs[:, 0, :], inputs[:, 1, :]\n",
    "        \n",
    "        # Define rotation function\n",
    "        def rotationindex(n):\n",
    "            index = jnp.reshape(jnp.arange(0, n**2, 1), [n, n])\n",
    "            return jnp.concatenate([jnp.roll(index, shift=[-i,-i], axis=[0,1]) for i in range(n)], 0)\n",
    "        \n",
    "        rindex = lambda d: jnp.take(d, rotationindex(self.nx))\n",
    "        \n",
    "        Rs = jax.vmap(rindex)(R)\n",
    "        Rs = jnp.reshape(Rs, [-1, self.nx, self.nx])\n",
    "        Is = jax.vmap(rindex)(I)\n",
    "        Is = jnp.reshape(Is, [-1, self.nx, self.nx])\n",
    "        \n",
    "        def helper(pre, post, kernel2, kernel1, data):\n",
    "            return jnp.matmul(post, jnp.multiply(kernel2, jnp.matmul(jnp.multiply(data, pre), kernel1)))  \n",
    "        \n",
    "        output_polar = helper(self.pre1, self.post1, self.cos_kernel1, self.cos_kernel2, Rs) \\\n",
    "                      + helper(self.pre2, self.post2, self.sin_kernel1, self.sin_kernel2, Rs) \\\n",
    "                      + helper(self.pre3, self.post3, self.cos_kernel2, self.sin_kernel1, Is) \\\n",
    "                      + helper(self.pre4, self.post4, self.sin_kernel2, self.cos_kernel1, Is)\n",
    "        \n",
    "        output_polar = jnp.reshape(output_polar, (-1, self.nx, self.nx))\n",
    "        \n",
    "        # Convert from polar to Cartesian coordinates\n",
    "        def polar_to_cart(x):\n",
    "            x = jnp.reshape(x, (self.nx**2, 1))\n",
    "            x = self.cart_mat @ x\n",
    "            return jnp.reshape(x, (self.neta, self.neta))\n",
    "        \n",
    "        output_cart = jax.vmap(polar_to_cart)(output_polar)\n",
    "        return jnp.reshape(output_cart, (-1, self.neta, self.neta, 1))\n",
    "\n",
    "# Define the main model using Flax\n",
    "class MyModel(nn.Module):\n",
    "    nx: int\n",
    "    neta: int\n",
    "    cart_mat: jnp.ndarray\n",
    "    num_cnn: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.fstar_layer0 = Fstar(nx=self.nx, neta=self.neta, cart_mat=self.cart_mat)\n",
    "        self.fstar_layer1 = Fstar(nx=self.nx, neta=self.neta, cart_mat=self.cart_mat)\n",
    "        self.fstar_layer2 = Fstar(nx=self.nx, neta=self.neta, cart_mat=self.cart_mat)\n",
    "        \n",
    "        self.convs = [nn.Conv(features=6, kernel_size=(3, 3), padding='SAME') for _ in range(self.num_cnn - 1)]\n",
    "        self.final_conv = nn.Conv(features=1, kernel_size=(3, 3), padding='SAME')\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        y0 = self.fstar_layer0(inputs[:, :, :, 0])\n",
    "        y1 = self.fstar_layer1(inputs[:, :, :, 1])\n",
    "        y2 = self.fstar_layer2(inputs[:, :, :, 2])\n",
    "        \n",
    "        y = jnp.concatenate([y0, y1, y2], axis = -1)\n",
    "\n",
    "        for conv_layer in self.convs:\n",
    "            tmp = conv_layer(y)\n",
    "            tmp = jax.nn.relu(tmp)\n",
    "            y = jnp.concatenate([y, tmp], axis = -1)\n",
    "        \n",
    "        y = self.final_conv(y)\n",
    "\n",
    "        return y[:,:,:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df58a7ff-8882-4061-b06f-88565528991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = MyModel(nx, neta, cart_mat, 8)\n",
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, inp_rng, init_rng = jax.random.split(rng, 3)\n",
    "inp = jax.random.normal(inp_rng, (batch_size, 2, 6400, 3))  \n",
    "# Define an optimizer\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "params = model.init(init_rng, inp)  # Initialize parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2e2b130-3b2c-459e-b7e8-f30bd728d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "\n",
    "model_state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                            params=params,\n",
    "                                            tx=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d2a2fc-6a8b-4c19-81d7-f4b13f18cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_acc(state, params, batch):\n",
    "    x, y = batch\n",
    "    # Obtain the logits and predictions of the model for the input data\n",
    "    pred = state.apply_fn(params, x)\n",
    "       \n",
    "    # Calculate the loss and accuracy\n",
    "    loss = jnp.mean((pred - y) ** 2)\n",
    "    acc = jnp.sqrt(loss/jnp.mean(y ** 2))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03a7bea3-f75e-4dcd-bac8-c31563619a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.01939696, dtype=float32), Array(0.97791815, dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "calculate_loss_acc(model_state, model_state.params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6369765d-6c95-44d9-804a-b4bc76a81aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def train_step(state, batch):\n",
    "    # Gradient function\n",
    "    grad_fn = jax.value_and_grad(calculate_loss_acc,  # Function to calculate the loss\n",
    "                                 argnums=1,  # Parameters are second argument of the function\n",
    "                                 has_aux=True  # Function has additional outputs, here accuracy\n",
    "                                )\n",
    "    # Determine gradients for current model, parameters and batch\n",
    "    (loss, acc), grads = grad_fn(state, state.params, batch)\n",
    "    # Perform parameter update with gradients and optimizer\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    # Return state and any other value we might want\n",
    "    return state, loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c3d478-6432-456d-b16b-c38bc70822df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def eval_step(state, batch):\n",
    "    # Determine the accuracy\n",
    "    _, acc = calculate_loss_acc(state, state.params, batch)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "785b7e38-4ba3-44fa-951e-b304370da38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(state, data_loader, num_epochs=100):\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            state, loss, acc = train_step(state, batch)\n",
    "        print(acc)\n",
    "            \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453354c6-5733-4793-a67c-8a98704cb229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25455862\n",
      "0.19897443\n",
      "0.17354843\n",
      "0.15688986\n",
      "0.13922612\n",
      "0.13644192\n",
      "0.12989336\n",
      "0.13155568\n",
      "0.1180487\n",
      "0.11828743\n",
      "0.11255716\n",
      "0.10880896\n",
      "0.109767854\n",
      "0.10609624\n",
      "0.09753256\n",
      "0.092296325\n",
      "0.08264763\n",
      "0.08392045\n",
      "0.09134734\n",
      "0.089241624\n",
      "0.09046501\n",
      "0.079866685\n",
      "0.080469795\n",
      "0.075873986\n",
      "0.07323089\n",
      "0.08085374\n",
      "0.07404339\n",
      "0.065801635\n",
      "0.074725606\n",
      "0.066407755\n",
      "0.06981976\n",
      "0.06988\n",
      "0.07045619\n",
      "0.062468685\n",
      "0.060781524\n",
      "0.06484609\n",
      "0.061060004\n",
      "0.060614735\n",
      "0.06206696\n",
      "0.05766756\n",
      "0.05866712\n",
      "0.05608634\n",
      "0.058511708\n",
      "0.05944217\n",
      "0.051764812\n",
      "0.055019785\n",
      "0.056162808\n",
      "0.05359541\n",
      "0.054161176\n",
      "0.05138499\n",
      "0.051150475\n",
      "0.04726951\n",
      "0.049116228\n",
      "0.05062388\n",
      "0.053629696\n",
      "0.047699884\n",
      "0.05012803\n",
      "0.048455406\n",
      "0.05057133\n",
      "0.048115037\n",
      "0.044389706\n",
      "0.047832746\n",
      "0.048106536\n",
      "0.046598658\n",
      "0.050254732\n",
      "0.048895407\n",
      "0.046088554\n",
      "0.045845576\n",
      "0.042230926\n",
      "0.042200796\n",
      "0.047221813\n",
      "0.045259368\n",
      "0.047108307\n",
      "0.04007353\n",
      "0.04360658\n",
      "0.04501091\n",
      "0.046463728\n",
      "0.043374684\n"
     ]
    }
   ],
   "source": [
    "trained_model_state = train_model(model_state, data_loader, num_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaafbb6-5903-4a8b-a4e4-55cf2f0ea077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2070ba-4ba1-4b5e-8968-00755f9925f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa75ed8-c2ee-4985-9a1b-d97bd1686f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d045834-1cce-431a-90ea-48cdbaf0195b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc5bbf-35e2-4ea6-a774-ac9a0b52ce44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e76b51-916b-47e7-a3b8-d8d8510232bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxflax",
   "language": "python",
   "name": "jaxflax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
