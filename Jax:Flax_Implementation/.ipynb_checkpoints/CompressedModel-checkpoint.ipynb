{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2980328-640d-47e6-afd2-d57030413ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from clu import metric_writers\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import lax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import optax\n",
    "import orbax.checkpoint as ocp\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py\n",
    "import natsort\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import geometric_transform\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3443b94d-40b8-40b0-8a77-bb6dfd050389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cuda(id=0), cuda(id=1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70692656-b0fa-4d2f-97e4-b6d703121375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the computational task.\n",
    "\n",
    "L = 4 # number of levels (even number)\n",
    "s = 5 # leaf size\n",
    "r = 3 # rank\n",
    "\n",
    "# Discretization of Omega (n_eta * n_eta).\n",
    "neta = (2**L)*s\n",
    "\n",
    "# Number of sources/detectors (n_sc).\n",
    "# Discretization of the domain of alpha in polar coordinates (n_theta * n_rho).\n",
    "# For simplicity, these values are set equal (n_sc = n_theta = n_rho), facilitating computation.\n",
    "nx = (2**L)*s\n",
    "\n",
    "# Standard deviation for the Gaussian blur.\n",
    "blur_sigma = 0.5\n",
    "\n",
    "# Batch size.\n",
    "batch_size = 16\n",
    "\n",
    "# Number of training datapoints.\n",
    "NTRAIN = 2000\n",
    "\n",
    "# Number of testing datapoints.\n",
    "NTEST = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5447cb-3303-487a-95eb-7ba6f59ada8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart_polar(coords):\n",
    "    \"\"\"\n",
    "    Transforms coordinates from Cartesian to polar coordinates with custom scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - coords: A tuple or list containing the (i, j) coordinates to be transformed.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple (rho, theta) representing the transformed coordinates.\n",
    "    \"\"\"\n",
    "    i, j = coords[0], coords[1]\n",
    "    # Calculate the radial distance with a scaling factor.\n",
    "    rho = 2 * np.sqrt((i - neta / 2) ** 2 + (j - neta / 2) ** 2) * nx / neta\n",
    "    # Calculate the angle in radians and adjust the scale to fit the specified range.\n",
    "    theta = ((np.arctan2((neta / 2 - j), (i - neta / 2))) % (2 * np.pi)) * nx / np.pi / 2\n",
    "    return theta, rho + neta // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe182499-eba6-4333-b448-7ce6dc6d8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to precompute the transformation matrix\n",
    "# Precompute the transformation matrix from polar coordinates to Cartesian coordiantes \n",
    "cart_mat = np.zeros((neta**2, nx, nx))\n",
    "\n",
    "for i in range(nx):\n",
    "    for j in range(nx):\n",
    "        # Create a dummy matrix with a single one at position (i, j) and zeros elsewhere.\n",
    "        mat_dummy = np.zeros((nx, nx))\n",
    "        mat_dummy[i, j] = 1\n",
    "        # Pad the dummy matrix in polar coordinates to cover the target space in Cartesian coordinates.\n",
    "        pad_dummy = np.pad(mat_dummy, ((0, 0), (neta // 2, neta // 2)), 'edge')\n",
    "        # Apply the geometric transformation to map the dummy matrix to polar coordinates\n",
    "        cart_mat[:, i, j] = geometric_transform(pad_dummy, cart_polar, output_shape=[neta, neta], mode='grid-wrap').flatten()\n",
    "\n",
    "cart_mat = np.reshape(cart_mat, (neta**2, nx**2))\n",
    "# Removing small values\n",
    "cart_mat = np.where(np.abs(cart_mat) > 0.001, cart_mat, 0)\n",
    "# Convert to sparse matrix in tensorflow\n",
    "#cart_mat = tf.sparse.from_dense(tf.cast(cart_mat, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24ca0d4-2e8e-4faf-b847-002bd2bc60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import sparse\n",
    "cart_mat = sparse.BCOO.fromdense(cart_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "520c961d-da9c-443b-aec0-8747b1f872fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "name = 'shepp_logan'\n",
    "\n",
    "# Loading and preprocessing perturbation data (eta)\n",
    "with h5py.File(f'{name}/eta.h5', 'r') as f:\n",
    "    # Read eta data, apply Gaussian blur, and reshape\n",
    "    eta_re = f[list(f.keys())[0]][:NTRAIN, :].reshape(-1, neta, neta)\n",
    "    blur_fn = lambda x: gaussian_filter(x, sigma=blur_sigma)\n",
    "    eta_re = np.stack([blur_fn(eta_re[i, :, :].T) for i in range(NTRAIN)]).astype('float32')\n",
    "\n",
    "# Loading and preprocessing scatter data (Lambda)\n",
    "with h5py.File(f'{name}/scatter.h5', 'r') as f:\n",
    "    keys = natsort.natsorted(f.keys())\n",
    "\n",
    "    # Process real part of scatter data\n",
    "    tmp1 = f[keys[3]][:NTRAIN, :]\n",
    "    tmp2 = f[keys[4]][:NTRAIN, :]\n",
    "    tmp3 = f[keys[5]][:NTRAIN, :]\n",
    "    scatter_re = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "\n",
    "    # Process imaginary part of scatter data\n",
    "    tmp1 = f[keys[0]][:NTRAIN, :]\n",
    "    tmp2 = f[keys[1]][:NTRAIN, :]\n",
    "    tmp3 = f[keys[2]][:NTRAIN, :]\n",
    "    scatter_im = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "    \n",
    "    # Combine real and imaginary parts\n",
    "    scatter = np.stack((scatter_re, scatter_im), axis=-2).astype('float32')\n",
    "    \n",
    "# Clean up temporary variables to free memory\n",
    "del scatter_re, scatter_im, tmp1, tmp2, tmp3\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "dataset = [(scatter[i,:,:,:], eta_re[i,:,:]) for i in range(NTRAIN)]\n",
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43970ad0-f759-4cc0-95de-f3efda8f7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class V(nn.Module):\n",
    "    r: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        n, s = x.shape[2], x.shape[3]\n",
    "\n",
    "        init_fn = nn.initializers.glorot_uniform()\n",
    "        vr1 = self.param('vr1', init_fn, (n, s, self.r))\n",
    "        vi1 = self.param('vi1', init_fn, (n, s, self.r))\n",
    "        vr2 = self.param('vr2', init_fn, (n, s, self.r))\n",
    "        vi2 = self.param('vi2', init_fn, (n, s, self.r))\n",
    "        vr3 = self.param('vr3', init_fn, (n, s, self.r))\n",
    "        vi3 = self.param('vi3', init_fn, (n, s, self.r))\n",
    "        vr4 = self.param('vr4', init_fn, (n, s, self.r))\n",
    "        vi4 = self.param('vi4', init_fn, (n, s, self.r))\n",
    "\n",
    "        x_re, x_im = x[..., 0], x[..., 1]\n",
    "\n",
    "        y_re_1 = jnp.einsum('...iaj,ajk->...iak', x_re, vr1)\n",
    "        y_re_1 = jnp.einsum('abj...i,bjk->abk...i', y_re_1, vr1)\n",
    "        y_re_2 = jnp.einsum('...iaj,ajk->...iak', x_re, vi1)\n",
    "        y_re_2 = jnp.einsum('abj...i,bjk->abk...i', y_re_2, vi1)\n",
    "        y_re_3 = jnp.einsum('...iaj,ajk->...iak', x_im, vi2)\n",
    "        y_re_3 = jnp.einsum('abj...i,bjk->abk...i', y_re_3, vr2)\n",
    "        y_re_4 = jnp.einsum('...iaj,ajk->...iak', x_im, vr2)\n",
    "        y_re_4 = jnp.einsum('abj...i,bjk->abk...i', y_re_4, vi2)\n",
    "        y_re = y_re_1+y_re_2+y_re_3+y_re_4\n",
    "        \n",
    "        y_im_1 = jnp.einsum('...iaj,ajk->...iak', x_im, vr3)\n",
    "        y_im_1 = jnp.einsum('abj...i,bjk->abk...i', y_im_1, vr3)\n",
    "        y_im_2 = jnp.einsum('...iaj,ajk->...iak', x_im, vi3)\n",
    "        y_im_2 = jnp.einsum('abj...i,bjk->abk...i', y_im_2, vi3)\n",
    "        y_im_3 = jnp.einsum('...iaj,ajk->...iak', x_re, vi4)\n",
    "        y_im_3 = jnp.einsum('abj...i,bjk->abk...i', y_im_3, vr4)\n",
    "        y_im_4 = jnp.einsum('...iaj,ajk->...iak', x_re, vr4)\n",
    "        y_im_4 = jnp.einsum('abj...i,bjk->abk...i', y_im_4, vi4)\n",
    "        y_im = y_im_1+y_im_2+y_im_3+y_im_4\n",
    "        \n",
    "        y = jnp.stack([y_re, y_im], axis=-1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92aca7f1-20ac-4d05-aa55-d7d485938493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputing indices used for grouping neighboring blocks prior to applying Layer Hs.\n",
    "def build_permutation_indices(L, l):\n",
    "    delta = 2**(L-l-1)\n",
    "    tmp = np.tile(np.arange(2)*delta, delta)\n",
    "    tmp += np.repeat(np.arange(delta), 2)\n",
    "    tmp = np.tile(tmp, 2**l)\n",
    "    tmp += np.repeat(np.arange(2**l)*(2**(L-l)), 2**(L-l))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51957f09-589a-47c5-bc30-d9fd5b1491ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H(nn.Module):\n",
    "    L: int\n",
    "    l: int\n",
    "\n",
    "    def setup(self):\n",
    "        # Compute permutation indices\n",
    "        self.perm_idx = build_permutation_indices(self.L, self.l)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # Placeholder for actual input shape dependent variables\n",
    "        m = x.shape[2] // 2\n",
    "        s = x.shape[3] * 2\n",
    "\n",
    "        # Define weights\n",
    "        init_fn = nn.initializers.glorot_uniform()\n",
    "        hr1 = self.param('hr1', init_fn, (m, s, s))\n",
    "        hi1 = self.param('hi1', init_fn, (m, s, s))\n",
    "        hr2 = self.param('hr2', init_fn, (m, s, s))\n",
    "        hi2 = self.param('hi2', init_fn, (m, s, s))\n",
    "        hr3 = self.param('hr3', init_fn, (m, s, s))\n",
    "        hi3 = self.param('hi3', init_fn, (m, s, s))\n",
    "        hr4 = self.param('hr4', init_fn, (m, s, s))\n",
    "        hi4 = self.param('hi4', init_fn, (m, s, s))\n",
    "\n",
    "        # Apply permutations\n",
    "        x = x.take(self.perm_idx, axis=1).take(self.perm_idx, axis=3)\n",
    "        \n",
    "        # Reshape operation\n",
    "        x = x.reshape((-1, m, s, m, s, 2))\n",
    "        # Split real and imaginary parts for processing\n",
    "        x_re, x_im = x[..., 0], x[..., 1]\n",
    "        \n",
    "        y_re_1 = jnp.einsum('...iaj,ajk->...iak', x_re, hr1)\n",
    "        y_re_1 = jnp.einsum('abj...i,bjk->abk...i', y_re_1, hr1)\n",
    "        y_re_2 = jnp.einsum('...iaj,ajk->...iak', x_re, hi1)\n",
    "        y_re_2 = jnp.einsum('abj...i,bjk->abk...i', y_re_2, hi1)\n",
    "        y_re_3 = jnp.einsum('...iaj,ajk->...iak', x_im, hi2)\n",
    "        y_re_3 = jnp.einsum('abj...i,bjk->abk...i', y_re_3, hr2)\n",
    "        y_re_4 = jnp.einsum('...iaj,ajk->...iak', x_im, hr2)\n",
    "        y_re_4 = jnp.einsum('abj...i,bjk->abk...i', y_re_4, hi2)\n",
    "        y_re = y_re_1+y_re_2+y_re_3+y_re_4\n",
    "        \n",
    "        y_im_1 = jnp.einsum('...iaj,ajk->...iak', x_im, hr3)\n",
    "        y_im_1 = jnp.einsum('abj...i,bjk->abk...i', y_im_1, hr3)\n",
    "        y_im_2 = jnp.einsum('...iaj,ajk->...iak', x_im, hi3)\n",
    "        y_im_2 = jnp.einsum('abj...i,bjk->abk...i', y_im_2, hi3)\n",
    "        y_im_3 = jnp.einsum('...iaj,ajk->...iak', x_re, hi4)\n",
    "        y_im_3 = jnp.einsum('abj...i,bjk->abk...i', y_im_3, hr4)\n",
    "        y_im_4 = jnp.einsum('...iaj,ajk->...iak', x_re, hr4)\n",
    "        y_im_4 = jnp.einsum('abj...i,bjk->abk...i', y_im_4, hi4)\n",
    "        y_im = y_im_1+y_im_2+y_im_3+y_im_4\n",
    "        \n",
    "        y = jnp.stack([y_re, y_im], axis=-1)\n",
    "\n",
    "        n = m * 2\n",
    "        r = s // 2\n",
    "        y = y.reshape((-1, n, r, n, r, 2))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0afc31ac-a6fc-4225-b803-641de473db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputing indices used for redistributing blocks according to the transformation represented by x -> M*xM.\n",
    "def build_switch_indices(L):\n",
    "    L = L // 2\n",
    "    tmp = np.arange(2**L)*(2**L)\n",
    "    tmp = np.tile(tmp, 2**L)\n",
    "    tmp += np.repeat(np.arange(2**L), 2**L)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1692047d-05c6-4a01-99b5-371b7d265b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        n, r = x.shape[2], x.shape[3]\n",
    "\n",
    "        # Initialize weights\n",
    "        init_fn = nn.initializers.glorot_uniform()\n",
    "        mr1 = self.param('mr1', init_fn, (n, r, r))\n",
    "        mi1 = self.param('mi1', init_fn, (n, r, r))\n",
    "        mr2 = self.param('mr2', init_fn, (n, r, r))\n",
    "        mi2 = self.param('mi2', init_fn, (n, r, r))\n",
    "        mr3 = self.param('mr3', init_fn, (n, r, r))\n",
    "        mi3 = self.param('mi3', init_fn, (n, r, r))\n",
    "        mr4 = self.param('mr4', init_fn, (n, r, r))\n",
    "        mi4 = self.param('mi4', init_fn, (n, r, r))\n",
    "\n",
    "        x_re, x_im = x[..., 0], x[..., 1]\n",
    "\n",
    "        y_re_1 = jnp.einsum('...iaj,ajk->...iak', x_re, mr1)\n",
    "        y_re_1 = jnp.einsum('abj...i,bjk->abk...i', y_re_1, mr1)\n",
    "        y_re_2 = jnp.einsum('...iaj,ajk->...iak', x_re, mi1)\n",
    "        y_re_2 = jnp.einsum('abj...i,bjk->abk...i', y_re_2, mi1)\n",
    "        y_re_3 = jnp.einsum('...iaj,ajk->...iak', x_im, mi2)\n",
    "        y_re_3 = jnp.einsum('abj...i,bjk->abk...i', y_re_3, mr2)\n",
    "        y_re_4 = jnp.einsum('...iaj,ajk->...iak', x_im, mr2)\n",
    "        y_re_4 = jnp.einsum('abj...i,bjk->abk...i', y_re_4, mi2)\n",
    "        y_re = y_re_1+y_re_2+y_re_3+y_re_4\n",
    "        \n",
    "        y_im_1 = jnp.einsum('...iaj,ajk->...iak', x_im, mr3)\n",
    "        y_im_1 = jnp.einsum('abj...i,bjk->abk...i', y_im_1, mr3)\n",
    "        y_im_2 = jnp.einsum('...iaj,ajk->...iak', x_im, mi3)\n",
    "        y_im_2 = jnp.einsum('abj...i,bjk->abk...i', y_im_2, mi3)\n",
    "        y_im_3 = jnp.einsum('...iaj,ajk->...iak', x_re, mi4)\n",
    "        y_im_3 = jnp.einsum('abj...i,bjk->abk...i', y_im_3, mr4)\n",
    "        y_im_4 = jnp.einsum('...iaj,ajk->...iak', x_re, mr4)\n",
    "        y_im_4 = jnp.einsum('abj...i,bjk->abk...i', y_im_4, mi4)\n",
    "        y_im = y_im_1+y_im_2+y_im_3+y_im_4\n",
    "        \n",
    "        y = jnp.stack([y_re, y_im], axis=-1)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd135331-a0d7-4402-8527-7a5798cbf383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    L: int\n",
    "    l: int\n",
    "\n",
    "    def setup(self):\n",
    "        # Setup is called once to create parameters, we'll store perm_idx here but its creation is static\n",
    "        self.perm_idx = build_permutation_indices(self.L, self.l)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # Dimensions need to be dynamically inferred from 'x'\n",
    "        m = x.shape[2] // 2\n",
    "        s = x.shape[3] * 2\n",
    "\n",
    "        # Initialize weights\n",
    "        init_fn = nn.initializers.glorot_uniform()\n",
    "        gr1 = self.param('gr1', init_fn, (m, s, s))\n",
    "        gi1 = self.param('gi1', init_fn, (m, s, s))\n",
    "        gr2 = self.param('gr2', init_fn, (m, s, s))\n",
    "        gi2 = self.param('gi2', init_fn, (m, s, s))\n",
    "        gr3 = self.param('gr3', init_fn, (m, s, s))\n",
    "        gi3 = self.param('gi3', init_fn, (m, s, s))\n",
    "        gr4 = self.param('gr4', init_fn, (m, s, s))\n",
    "        gi4 = self.param('gi4', init_fn, (m, s, s))\n",
    "\n",
    "        # Reshape and perform operations\n",
    "        x = x.reshape((-1, m, s, m, s, 2))\n",
    "        x_re, x_im = x[..., 0], x[..., 1]\n",
    "\n",
    "        y_re_1 = jnp.einsum('...iaj,ajk->...iak', x_re, gr1)\n",
    "        y_re_1 = jnp.einsum('abj...i,bjk->abk...i', y_re_1, gr1)\n",
    "        y_re_2 = jnp.einsum('...iaj,ajk->...iak', x_re, gi1)\n",
    "        y_re_2 = jnp.einsum('abj...i,bjk->abk...i', y_re_2, gi1)\n",
    "        y_re_3 = jnp.einsum('...iaj,ajk->...iak', x_im, gi2)\n",
    "        y_re_3 = jnp.einsum('abj...i,bjk->abk...i', y_re_3, gr2)\n",
    "        y_re_4 = jnp.einsum('...iaj,ajk->...iak', x_im, gr2)\n",
    "        y_re_4 = jnp.einsum('abj...i,bjk->abk...i', y_re_4, gi2)\n",
    "        y_re = y_re_1+y_re_2+y_re_3+y_re_4\n",
    "        \n",
    "        y_im_1 = jnp.einsum('...iaj,ajk->...iak', x_im, gr3)\n",
    "        y_im_1 = jnp.einsum('abj...i,bjk->abk...i', y_im_1, gr3)\n",
    "        y_im_2 = jnp.einsum('...iaj,ajk->...iak', x_im, gi3)\n",
    "        y_im_2 = jnp.einsum('abj...i,bjk->abk...i', y_im_2, gi3)\n",
    "        y_im_3 = jnp.einsum('...iaj,ajk->...iak', x_re, gi4)\n",
    "        y_im_3 = jnp.einsum('abj...i,bjk->abk...i', y_im_3, gr4)\n",
    "        y_im_4 = jnp.einsum('...iaj,ajk->...iak', x_re, gr4)\n",
    "        y_im_4 = jnp.einsum('abj...i,bjk->abk...i', y_im_4, gi4)\n",
    "        y_im = y_im_1+y_im_2+y_im_3+y_im_4\n",
    "\n",
    "        y = jnp.stack([y_re, y_im], axis=-1)\n",
    "\n",
    "        # Final reshape and permutation\n",
    "        n, r = m * 2, s // 2\n",
    "        y = y.reshape((-1, n, r, n, r, 2))\n",
    "        y = y.take(self.perm_idx, axis=1).take(self.perm_idx, axis=3)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d8e4dcf-965e-4c57-8875-2c1e6df0646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class U(nn.Module):\n",
    "    s: int  # Size parameter\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # Extracting the shapes for weight initialization\n",
    "        n, r, c = x.shape[2], x.shape[3], x.shape[-1]\n",
    "        nx = n*self.s\n",
    "        \n",
    "        # Weight initialization\n",
    "        init_fn = nn.initializers.glorot_uniform()\n",
    "        ur1 = self.param('ur1', init_fn, (n, r, self.s))\n",
    "        ui1 = self.param('ui1', init_fn, (n, r, self.s))\n",
    "        ur2 = self.param('ur2', init_fn, (n, r, self.s))\n",
    "        ui2 = self.param('ui2', init_fn, (n, r, self.s))\n",
    "        ur3 = self.param('ur3', init_fn, (n, r, self.s))\n",
    "        ui3 = self.param('ui3', init_fn, (n, r, self.s))\n",
    "        ur4 = self.param('ur4', init_fn, (n, r, self.s))\n",
    "        ui4 = self.param('ui4', init_fn, (n, r, self.s))\n",
    "\n",
    "        # Splitting real and imaginary parts\n",
    "        x_re, x_im = x[..., 0], x[..., 1]\n",
    "\n",
    "        # Performing the einsum operations\n",
    "        y_re_1 = jnp.einsum('...iaj,ajk->...iak', x_re, ur1)\n",
    "        y_re_1 = jnp.einsum('abj...i,bjk->abk...i', y_re_1, ur1)\n",
    "        y_re_2 = jnp.einsum('...iaj,ajk->...iak', x_re, ui2)\n",
    "        y_re_2 = jnp.einsum('abj...i,bjk->abk...i', y_re_2, ui2)\n",
    "        y_re_3 = jnp.einsum('...iaj,ajk->...iak', x_im, ui3)\n",
    "        y_re_3 = jnp.einsum('abj...i,bjk->abk...i', y_re_3, ur3)\n",
    "        y_re_4 = jnp.einsum('...iaj,ajk->...iak', x_im, ur4)\n",
    "        y_re_4 = jnp.einsum('abj...i,bjk->abk...i', y_re_4, ui4)\n",
    "        y_re = y_re_1+y_re_2+y_re_3+y_re_4\n",
    "        # Final sum of y_re components\n",
    "        y_re = y_re_1 + y_re_2 + y_re_3 + y_re_4\n",
    "\n",
    "        return y_re.reshape((-1, nx, nx, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25629094-e542-4f3e-9553-4276fec5af83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e72b6-2b15-422a-88ae-5f5a4f223f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fstar(nn.Module):\n",
    "    L: int\n",
    "    s: int\n",
    "    r: int\n",
    "    NUM_RESNET: int\n",
    "    cart_mat: jnp.ndarray\n",
    "    r_index: jnp.ndarray\n",
    "    \n",
    "    def setup(self):\n",
    "        self.n = 2**self.L\n",
    "        self.nx = (2**self.L)*self.s\n",
    "        self.neta = (2**self.L)*self.s\n",
    "        self.V = V(self.r)\n",
    "        self.Hs = [H(self.L, l) for l in range(self.L-1, self.L//2-1, -1)]\n",
    "        self.Ms = [M() for _ in range(2 * self.NUM_RESNET)]\n",
    "        self.Gs = [G(self.L, l) for l in range(self.L//2, self.L)]\n",
    "        self.U = U(self.s)\n",
    "        self.switch_idx = build_switch_indices(self.L)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \n",
    "        def helper(input):\n",
    "            y = jnp.reshape(jnp.take(input, r_index, axis=0), (-1, self.nx, self.nx, 2))\n",
    "\n",
    "            y = self.V(y)\n",
    "            \n",
    "            for h in self.Hs:\n",
    "                y = h(y)\n",
    "                     \n",
    "            y = y.take(self.switch_idx, axis=1).take(self.switch_idx, axis=3)\n",
    "            for m in self.Ms:\n",
    "                y = m(y) if m is self.Ms[-1] else y + nn.relu(m(y))\n",
    "        \n",
    "            for g in self.Gs:\n",
    "                y = g(y)\n",
    "        \n",
    "            y = self.U(y)\n",
    "            \n",
    "            y = jnp.diagonal(y, axis1 = 1, axis2 = 2)\n",
    "            y = jnp.reshape(y, (-1, self.nx**2, 1))\n",
    "            y = self.cart_mat @ y\n",
    "            \n",
    "            return jnp.reshape(x, (self.neta, self.neta, 1))\n",
    "\n",
    "        return jax.vmap(helper)(inputs)\n",
    "\n",
    "# Define the main model using Flax\n",
    "class MyModel(nn.Module):\n",
    "    L: int\n",
    "    s: int\n",
    "    r: int\n",
    "    NUM_RESNET: int\n",
    "    cart_mat: jnp.ndarray\n",
    "    r_index: jnp.ndarray\n",
    "\n",
    "    def setup(self):\n",
    "        self.fstar_layer0 = Fstar(L=self.L, s=self.s, r=self.r, NUM_RESNET = self.NUM_RESNET, cart_mat=self.cart_mat, r_index=self.r_index)\n",
    "        self.fstar_layer1 = Fstar(L=self.L, s=self.s, r=self.r, NUM_RESNET = self.NUM_RESNET, cart_mat=self.cart_mat, r_index=self.r_index)\n",
    "        self.fstar_layer2 = Fstar(L=self.L, s=self.s, r=self.r, NUM_RESNET = self.NUM_RESNET, cart_mat=self.cart_mat, r_index=self.r_index)\n",
    "        self.convs = [nn.Conv(features=6, kernel_size=(3, 3), padding='SAME') for _ in range(9)]\n",
    "        self.final_conv = nn.Conv(features=1, kernel_size=(3, 3), padding='SAME')\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        y0 = self.fstar_layer0(inputs[:, :, :, 0])\n",
    "        y1 = self.fstar_layer1(inputs[:, :, :, 1])\n",
    "        y2 = self.fstar_layer2(inputs[:, :, :, 2])\n",
    "        \n",
    "        y = jnp.concatenate([y0, y1, y2], axis = -1)\n",
    "\n",
    "        for conv_layer in self.convs:\n",
    "            tmp = conv_layer(y)\n",
    "            tmp = jax.nn.relu(tmp)\n",
    "            y = jnp.concatenate([y, tmp], axis = -1)\n",
    "        \n",
    "        y = self.final_conv(y)\n",
    "        \n",
    "        return y[:,:,:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed5080f4-49bd-471c-8c0b-b73b9acabf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotationindex(n):\n",
    "    index = jnp.reshape(jnp.arange(0, n**2, 1), [n, n])\n",
    "    return jnp.concatenate([jnp.roll(index, shift=[-i,-i], axis=[0,1]) for i in range(n)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87dd6c08-4941-4c4e-8adf-8b054627af0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[   0,    1,    2, ...,   77,   78,   79],\n",
       "       [  80,   81,   82, ...,  157,  158,  159],\n",
       "       [ 160,  161,  162, ...,  237,  238,  239],\n",
       "       ...,\n",
       "       [6159, 6080, 6081, ..., 6156, 6157, 6158],\n",
       "       [6239, 6160, 6161, ..., 6236, 6237, 6238],\n",
       "       [6319, 6240, 6241, ..., 6316, 6317, 6318]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_index = rotationindex(80)\n",
    "r_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a514b529-6848-489c-9b3a-4ade9fdfca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scatter[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a01ac7e-a3d2-45d8-9a13-e03654654193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1e538d5-9460-4b06-a605-ab8bfa2863bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = jnp.take(data, r_index, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f84bad3-196d-4d83-a40c-f1f0fbb74ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cdb4086-cea5-4db3-9e74-3167e175bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c2 = jnp.stack((r1, i1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a431ded-0140-49ab-a7d7-8e618467d985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 - c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df58a7ff-8882-4061-b06f-88565528991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = MyModel(L, s, r, 3, cart_mat, r_index)\n",
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, inp_rng, init_rng = jax.random.split(rng, 3)\n",
    "inp = jax.random.normal(inp_rng, (batch_size, 2, 6400, 3))  \n",
    "# Define an optimizer\n",
    "optimizer = optax.adam(learning_rate=4e-3)\n",
    "params = model.init(init_rng, inp)  # Initialize parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2e2b130-3b2c-459e-b7e8-f30bd728d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "\n",
    "model_state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                            params=params,\n",
    "                                            tx=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81d2a2fc-6a8b-4c19-81d7-f4b13f18cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_acc(state, params, batch):\n",
    "    x, y = batch\n",
    "    # Obtain the logits and predictions of the model for the input data\n",
    "    pred = state.apply_fn(params, x)\n",
    "       \n",
    "    # Calculate the loss and accuracy\n",
    "    loss = jnp.mean((pred - y) ** 2)\n",
    "    acc = jnp.sqrt(loss/jnp.mean(y ** 2))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03a7bea3-f75e-4dcd-bac8-c31563619a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.01913041, dtype=float32), Array(1., dtype=float32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "calculate_loss_acc(model_state, model_state.params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6369765d-6c95-44d9-804a-b4bc76a81aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def train_step(state, batch):\n",
    "    # Gradient function\n",
    "    grad_fn = jax.value_and_grad(calculate_loss_acc,  # Function to calculate the loss\n",
    "                                 argnums=1,  # Parameters are second argument of the function\n",
    "                                 has_aux=True  # Function has additional outputs, here accuracy\n",
    "                                )\n",
    "    # Determine gradients for current model, parameters and batch\n",
    "    (loss, acc), grads = grad_fn(state, state.params, batch)\n",
    "    # Perform parameter update with gradients and optimizer\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    # Return state and any other value we might want\n",
    "    return state, loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84c3d478-6432-456d-b16b-c38bc70822df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def eval_step(state, batch):\n",
    "    # Determine the accuracy\n",
    "    _, acc = calculate_loss_acc(state, state.params, batch)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "785b7e38-4ba3-44fa-951e-b304370da38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(state, data_loader, num_epochs=100):\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            state, loss, acc = train_step(state, batch)\n",
    "        print(acc)\n",
    "            \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453354c6-5733-4793-a67c-8a98704cb229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8835075\n",
      "0.8780626\n",
      "0.57185066\n",
      "0.28665906\n",
      "0.23034663\n",
      "0.2321662\n",
      "0.2068171\n",
      "0.17213953\n",
      "0.17073564\n",
      "0.1839958\n",
      "0.15804748\n",
      "0.1711674\n",
      "0.1473232\n",
      "0.14383674\n",
      "0.1601862\n",
      "0.13681433\n",
      "0.13639821\n",
      "0.12729992\n",
      "0.11110984\n",
      "0.11529502\n",
      "0.101152524\n",
      "0.11395437\n",
      "0.09848287\n",
      "0.091624506\n",
      "0.09400712\n",
      "0.08499524\n",
      "0.09534076\n",
      "0.07303455\n",
      "0.0848759\n",
      "0.083433114\n",
      "0.09147592\n",
      "0.08247699\n",
      "0.0744942\n",
      "0.076485455\n",
      "0.08341152\n",
      "0.081816405\n",
      "0.07906338\n",
      "0.074586496\n",
      "0.08885229\n",
      "0.0724868\n",
      "0.077469006\n",
      "0.07469498\n"
     ]
    }
   ],
   "source": [
    "trained_model_state = train_model(model_state, data_loader, num_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaafbb6-5903-4a8b-a4e4-55cf2f0ea077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2070ba-4ba1-4b5e-8968-00755f9925f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa75ed8-c2ee-4985-9a1b-d97bd1686f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d045834-1cce-431a-90ea-48cdbaf0195b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc5bbf-35e2-4ea6-a774-ac9a0b52ce44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e76b51-916b-47e7-a3b8-d8d8510232bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxflax",
   "language": "python",
   "name": "jaxflax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
